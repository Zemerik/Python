# Ethical Notes

- Always check robots.txt (https://example.com/robots.txt)
- Limit request rate (add delays between requests)
- Identify your scraper in User-Agent header
- Cache pages to avoid repeated requests
- Respect website terms of service